---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a 2nd-year(2023 Spring-now) Ph.D student in Computer Science at [University of Notre Dame](https://www.nd.edu/), advised by [Prof. Xiangliang Zhang](https://sites.nd.edu/xiangliang-zhang/). Before this, I received my B.E. degree in Computer Science and Engineering at the [University of Electronic Science and Technology of China (UESTC)](https://en.uestc.edu.cn/) and my M.S degree in Computer Science at [King Abdullah University of Science and Technology (KAUST)](https://www.kaust.edu.sa/en).


I am deeply interested in trustworthy large language models (LLMs) and adversarial machine learning. My work focuses on developing innovative methodologies in adversarial learning and LLMs to ensure the robustness and reliability of AI systems. This involves creating algorithms to detect and mitigate adversarial attacks and designing frameworks to enhance the safety of LLMs. My goal is to address critical challenges in AI by making machine learning models more resilient and trustworthy in real-world applications. Currently, I am engaged in the ND-IBM Tech Ethics Lab Collaborative Project, where I aim to extend the trustworthiness of LLMs to real-world safety-critical applications, such as lab safety, beyond the traditional focus areas.

<blockquote style="font-size: 16px; line-height: 1.6;">
    I am seeking potential research collaborations and the position of industry research intern. If you are interested, please <a href="mailto:yzhou25@nd.edu">contact me</a>.
</blockquote>


# 🔥 News
- *2024.09*: &nbsp;🎉🎉 One first-author paper has been accepted by EMNLP 2024!
- *2024.05*: &nbsp;🎉🎉 One Paper is accepted by ACL 2024!
- *2024.05*: &nbsp;🎉🎉 One first-author paper has been accepted by ICML 2024!
- *2022.12*: &nbsp;🎉🎉 One Paper is accepted by AAAI 2023!
- *2022.10*: &nbsp;🎉🎉 One Paper is accepted by BigData 2022!
- *2022.01*: &nbsp;🎉🎉 One paper is accepted by ICLR 2022!

# 📝 Publications 

See more publications in my [Google Scholar](https://scholar.google.com/citations?user=t8iRCLUAAAAJ&hl=en)

- ![ICML 2024](https://img.shields.io/badge/ICML-2024-A84111) [Attack-free Evaluating and Enhancing Adversarial Robustness on Categorical Data](https://openreview.net/pdf?id=8ERo4jph0A), **Yujun Zhou**, Yufei Han, Haomin Zhuang, Hongyan Bao, Xiangliang Zhang
- ![EMNLP 2024](https://img.shields.io/badge/EMNLP-2024-e87213) [Defending Jailbreak Prompts via In-Context Adversarial Game](https://arxiv.org/abs/2402.13148), **Yujun Zhou**, Yufei Han, Haomin Zhuang, Taicheng Guo, Kehan Guo, Zhenwen Liang, Hongyan Bao, and Xiangliang Zhang
- ![Arxiv Preprint](https://img.shields.io/badge/Arxiv-Preprint-b4d723) [LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs](https://arxiv.org/abs/2410.14182), **Yujun Zhou**, Jingdong Yang, Kehan Guo, Pin-Yu Chen, Tian Gao, Werner Geyer, Nuno Moniz, Nitesh V Chawla, Xiangliang Zhang
- ![NeurIPS 2024 Spotlight](https://img.shields.io/badge/NeurIPS-2024-2024) [Can LLMs Solve Molecule Puzzles? A Multimodal Benchmark for Molecular Structure Elucidation](https://kehanguo2.github.io/Molpuzzle.io/), Kehan Guo, Bozhao Nan, **Yujun Zhou**, Taicheng Guo, Zhichun Guo, Mihir Surve, Zhenwen Liang, Nitesh V. Chawla, Olaf Wiest, Xiangliang Zhang

- ![ACL 2024](https://img.shields.io/badge/ACL-2024-A27D46) [SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark](https://scemqa.github.io/), Zhenwen Liang, Kehan Guo, Gang Liu, Taicheng Guo, **Yujun Zhou**, Tianyu Yang, Jiajun Jiao, Renjie Pi, Jipeng Zhang, Xiangliang Zhang
- ![AAAI 2023](https://img.shields.io/badge/AAAI-2023-f3d6a3)[Towards efficient and domain-agnostic evasion attack with high-dimensional categorical inputs](https://ojs.aaai.org/index.php/AAAI/article/download/25828/25600), Hongyan Bao, Yufei Han, **Yujun Zhou**, Xin Gao, Xiangliang Zhang
- ![ICLR 2022](https://img.shields.io/badge/ICLR-2022-d7a2b3) [Towards understanding the robustness against evasion attack on categorical data](https://openreview.net/pdf?id=BmJV7kyAmg), Hongyan Bao, Yufei Han, **Yujun Zhou**, Yun Shen, Xiangliang Zhang

<!--# 🎖 Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. -->

# 📖 Educations
- *2023.01 - Present*, Ph.D, <img src='images/Notre_Dame.png' style='width: 1.2em;'> [University of Notre Dame](https://www.nd.edu/)  
- *2021.09 - 2022.12*, M.S,  <img src='images/kaust.png' style='width: 1.2em;'> [King Abdullah University of Science and Technology](https://www.kaust.edu.sa/en)
- *2017.09 - 2021.06*, B.Eng,  <img src='images/uestc.png' style='width: 1.2em;'> [University of Electronic Science and Technology of China](https://en.uestc.edu.cn/) 

<!--# 💬 Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)-->

<!--# 💻 Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.-->
